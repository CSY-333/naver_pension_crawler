# Naver News Pension Crawler

A robust web crawler for collecting Naver News articles about "êµ­ë¯¼ì—°ê¸ˆ" (National Pension) from sections 100 (Politics), 101 (Economy), and 102 (Society). It collects article metadata, comments (for high-engagement articles), and demographic summaries.

## Features

- **Targeted Crawling**: Scans specific Naver News sections.
- **Filtering**: Filters articles by keywords ("êµ­ë¯¼ì—°ê¸ˆ", "êµ­ë¯¼ ì—°ê¸ˆ").
- **Comment Collection**: Collects comments if count >= 100.
- **Demographics**: Extracts gender and age distribution for articles.
- **Polite Crawling**: Random delays and user-agent rotation.
- **Robustness**: Handles network errors and UI variations.
- **Data Export**: Saves to CSV (UTF-8 BOM for Excel).

## Prerequisites

- Python 3.11+
- Playwright

## Installation

1. Create a virtual environment (optional but recommended):

   ```powershell
   python -m venv venv
   .\venv\Scripts\activate
   ```

2. Install dependencies:

   ```powershell
   pip install -r requirements.txt
   ```

3. Install Playwright browsers:
   ```powershell
   playwright install chromium
   ```

## ðŸ“œ Project Rules

This project follows strict engineering standards defined in [.agent/rules/rules.md](.agent/rules/rules.md).
**Core principles:**

1. **TDD & SOLID**: All code must comprise unit tests and follow modular design.
2. **Operational Stability**: Incremental saving and crash recovery are mandatory.
3. **Async First**: Prefer `aiohttp` for network operations.

## Usage

### standard Run

Run the crawler using the provided batch script:

```powershell
.\crawl.bat
```

Or directly via Python:

```powershell
python src/main.py
```

### Configuration

Edit `config/config.yaml` to change parameters:

- `articles_per_section`: Number of articles to scan per section.
- `comment_threshold`: Minimum comments to trigger collection.
- `keywords`: List of title keywords to filter by.
- `headless`: Set to `false` to see the browser while crawling.

### Output

Data is saved to `C:/Users/maudi/OneDrive/ë¬¸ì„œ/GPR/`:

- `articles_pension.csv`: Article metadata and demographics.
- `comments_pension.csv`: Collected comments.

Logs and run summaries are saved in `logs/`.

## Project Structure

```
naver_pension_crawler/
â”œâ”€â”€ config/             # Configuration files
â”œâ”€â”€ logs/               # Run logs and JSON summaries
â”œâ”€â”€ src/                # Source code
â”‚   â”œâ”€â”€ crawler.py      # Main crawler logic
â”‚   â”œâ”€â”€ parsers.py      # HTML parsing logic
â”‚   â”œâ”€â”€ selectors.py    # CSS selectors
â”‚   â”œâ”€â”€ storage.py      # CSV export logic
â”‚   â”œâ”€â”€ report.py       # Reporting module
â”‚   â””â”€â”€ main.py         # Entry point
â”œâ”€â”€ tests/              # Tests
â”œâ”€â”€ requirements.txt    # Dependencies
â”œâ”€â”€ crawl.bat           # Execution script
â””â”€â”€ README.md           # Documentation
```
